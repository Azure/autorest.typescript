openapi: 3.0.0
info:
  title: OpenAI API
  version: 2.0.0
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
tags:
  - name: OpenAI
paths:
  /audio/transcriptions:
    post:
      tags:
        - OpenAI
      operationId: createTranscription
      summary: Transcribes audio into the input language.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateTranscriptionResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranscriptionRequest'
  /audio/translations:
    post:
      tags:
        - OpenAI
      operationId: createTranslation
      summary: Transcribes audio into the input language.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateTranslationResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranslationRequest'
  /chat/completions:
    post:
      tags:
        - OpenAI
      operationId: createChatCompletion
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
  /completions:
    post:
      tags:
        - OpenAI
      operationId: createCompletion
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateCompletionResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCompletionRequest'
      x-oaiMeta:
        name: Create chat completion
        group: chat
        returns: |-
          Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of
          [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.
        path: create
        examples:
          - title: No streaming
            request:
              curl: |-
                curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ]
              python: |-
                import os
                import openai
                openai.api_key = os.getenv("OPENAI_API_KEY")

                completion = openai.ChatCompletion.create(
                  model="VAR_model_id",
                  messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ]
                )

                print(completion.choices[0].message)
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const completion = await openai.chat.completions.create({
                    messages: [{ role: "system", content: "string" }],
                    model: "VAR_model_id",
                  });

                  console.log(completion.choices[0]);
                }

                main();
            response: |-
              {
                "id": "chatcmpl-123",
                "object": "chat.completion",
                "created": 1677652288,
                "model": "gpt-3.5-turbo-0613",
                "choices": [{
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "

              Hello there, how may I assist you today?",
                  },
                  "finish_reason": "stop"
                }],
                "usage": {
                  "prompt_tokens": 9,
                  "completion_tokens": 12,
                  "total_tokens": 21
                }
              }
          - title: Streaming
            request:
              curl: |-
                curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "stream": true
                }'
              python: |-
                import os
                import openai
                openai.api_key = os.getenv("OPENAI_API_KEY")

                completion = openai.ChatCompletion.create(
                  model="VAR_model_id",
                  messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ],
                  stream=True
                )

                for chunk in completion:
                  print(chunk.choices[0].delta)
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const completion = await openai.chat.completions.create({
                    model: "VAR_model_id",
                    messages: [
                      {"role": "system", "content": "You are a helpful assistant."},
                      {"role": "user", "content": "Hello!"}
                    ],
                    stream: true,
                  });

                  for await (const chunk of completion) {
                    console.log(chunk.choices[0].delta.content);
                  }
                }

                main();
            response: |-
              {
                "id": "chatcmpl-123",
                "object": "chat.completion.chunk",
                "created": 1677652288,
                "model": "gpt-3.5-turbo",
                "choices": [{
                  "index": 0,
                  "delta": {
                    "content": "Hello",
                  },
                  "finish_reason": "stop"
                }]
              }
  /edits:
    post:
      tags:
        - OpenAI
      operationId: createEdit
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEditResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEditRequest'
      deprecated: true
  /embeddings:
    post:
      tags:
        - OpenAI
      operationId: createEmbedding
      summary: Creates an embedding vector representing the input text.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
  /files:
    get:
      tags:
        - OpenAI
      operationId: listFiles
      summary: Returns a list of files that belong to the user's organization.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFilesResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
    post:
      tags:
        - OpenAI
      operationId: createFile
      summary: Returns a list of files that belong to the user's organization.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateFileRequest'
  /files/files/{file_id}:
    post:
      tags:
        - OpenAI
      operationId: retrieveFile
      summary: Returns information about a specific file.
      parameters:
        - name: file_id
          in: path
          required: true
          description: The ID of the file to use for this request.
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
    delete:
      tags:
        - OpenAI
      operationId: deleteFile
      summary: Delete a file
      parameters:
        - name: file_id
          in: path
          required: true
          description: The ID of the file to use for this request.
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFileResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /files/files/{file_id}/content:
    get:
      tags:
        - OpenAI
      operationId: downloadFile
      summary: Returns the contents of the specified file.
      parameters:
        - name: file_id
          in: path
          required: true
          description: The ID of the file to use for this request.
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                type: string
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /fine-tunes:
    post:
      tags:
        - OpenAI
      operationId: createFineTune
      summary: |-
        Creates a job that fine-tunes a specified model from a given dataset.

        Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

        [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTune'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuneRequest'
      deprecated: true
    get:
      tags:
        - OpenAI
      operationId: listFineTunes
      summary: List your organization's fine-tuning jobs
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTunesResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      deprecated: true
  /fine-tunes/{fine_tune_id}:
    get:
      tags:
        - OpenAI
      operationId: retrieveFineTune
      summary: |-
        Gets info about the fine-tune job.

        [Learn more about fine-tuning](/docs/guides/legacy-fine-tuning)
      parameters:
        - name: fine_tune_id
          in: path
          required: true
          description: The ID of the fine-tune job
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTune'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      deprecated: true
  /fine-tunes/{fine_tune_id}/cancel:
    post:
      tags:
        - OpenAI
      operationId: cancelFineTune
      summary: Immediately cancel a fine-tune job.
      parameters:
        - name: fine_tune_id
          in: path
          required: true
          description: The ID of the fine-tune job to cancel
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTune'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      deprecated: true
  /fine-tunes/{fine_tune_id}/events:
    get:
      tags:
        - OpenAI
      operationId: listFineTuneEvents
      summary: Get fine-grained status updates for a fine-tune job.
      parameters:
        - name: fine_tune_id
          in: path
          required: true
          description: The ID of the fine-tune job to get events for.
          schema:
            type: string
        - name: stream
          in: query
          required: false
          description: |-
            Whether to stream events for the fine-tune job. If set to true, events will be sent as
            data-only
            [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available. The stream will terminate with a `data: [DONE]` message when the
            job is finished (succeeded, cancelled, or failed).

            If set to false, only events generated so far will be returned.
          schema:
            type: boolean
            default: false
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuneEventsResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      deprecated: true
  /fine_tuning/jobs:
    post:
      tags:
        - OpenAI
      operationId: createFineTuningJob
      description: |-
        Creates a job that fine-tunes a specified model from a given dataset.

        Response includes details of the enqueued job including job status and the name of the
        fine-tuned models once complete.

        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningJobRequest'
    get:
      tags:
        - OpenAI
      operationId: listPaginatedFineTuningJobs
      parameters:
        - name: after
          in: query
          required: false
          description: Identifier for the last job from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          required: false
          description: Number of fine-tuning jobs to retrieve.
          schema:
            type: integer
            format: int64
            default: 20
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListPaginatedFineTuningJobsResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /fine_tuning/jobs/{fine_tuning_job_id}:
    get:
      tags:
        - OpenAI
      operationId: retrieveFineTuningJob
      summary: |-
        Get info about a fine-tuning job.

        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      parameters:
        - name: fine_tuning_job_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /fine_tuning/jobs/{fine_tuning_job_id}/cancel:
    post:
      tags:
        - OpenAI
      operationId: cancelFineTuningJob
      summary: Immediately cancel a fine-tune job.
      parameters:
        - name: fine_tuning_job_id
          in: path
          required: true
          description: The ID of the fine-tuning job to cancel.
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /fine_tuning/jobs/{fine_tuning_job_id}/events:
    get:
      tags:
        - OpenAI
      operationId: listFineTuningEvents
      summary: Get status updates for a fine-tuning job.
      parameters:
        - name: fine_tuning_job_id
          in: path
          required: true
          description: The ID of the fine-tuning job to get events for.
          schema:
            type: string
        - name: after
          in: query
          required: false
          description: Identifier for the last event from the previous pagination request.
          schema:
            type: string
        - name: limit
          in: query
          required: false
          description: Number of events to retrieve.
          schema:
            type: integer
            default: 20
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobEventsResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /images/edits:
    post:
      tags:
        - OpenAI
      operationId: createImageEdit
      summary: Creates an edited or extended image given an original image and a prompt.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageEditRequest'
  /images/generations:
    post:
      tags:
        - OpenAI
      operationId: createImage
      summary: Creates an image given a prompt
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
  /images/variations:
    post:
      tags:
        - OpenAI
      operationId: createImageVariation
      summary: Creates an edited or extended image given an original image and a prompt.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageVariationRequest'
  /models:
    get:
      tags:
        - OpenAI
      operationId: listModels
      summary: |-
        Lists the currently available models, and provides basic information about each one such as the
        owner and availability.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListModelsResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /models/{model}:
    get:
      tags:
        - OpenAI
      operationId: retrieveModel
      summary: |-
        Retrieves a model instance, providing basic information about the model such as the owner and
        permissioning.
      parameters:
        - name: model
          in: path
          required: true
          description: The ID of the model to use for this request.
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
    delete:
      tags:
        - OpenAI
      operationId: deleteModel
      summary: Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.
      parameters:
        - name: model
          in: path
          required: true
          description: The model to delete
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteModelResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /moderations:
    post:
      tags:
        - OpenAI
      operationId: createModeration
      summary: Classifies if text violates OpenAI's Content Policy
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateModerationResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateModerationRequest'
security:
  - BearerAuth: []
components:
  schemas:
    ChatCompletionFunctionCallOption:
      type: object
      required:
        - name
      properties:
        name:
          type: string
          description: The name of the function to call.
    ChatCompletionFunctionParameters:
      type: object
      additionalProperties: {}
    ChatCompletionFunctions:
      type: object
      required:
        - name
        - parameters
      properties:
        name:
          type: string
          description: |-
            The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
            dashes, with a maximum length of 64.
        description:
          type: string
          description: |-
            A description of what the function does, used by the model to choose when and how to call the
            function.
        parameters:
          allOf:
            - $ref: '#/components/schemas/ChatCompletionFunctionParameters'
          description: |-
            The parameters the functions accepts, described as a JSON Schema object. See the
            [guide](/docs/guides/gpt/function-calling) for examples, and the
            [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation
            about the format.\n\nTo describe a function that accepts no parameters, provide the value
            `{\"type\": \"object\", \"properties\": {}}`.
    ChatCompletionRequestMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum:
            - system
            - user
            - assistant
            - function
          description: The role of the messages author. One of `system`, `user`, `assistant`, or `function`.
        content:
          type: string
          nullable: true
          description: |-
            The contents of the message. `content` is required for all messages, and may be null for
            assistant messages with function calls.
        name:
          type: string
          description: |-
            The name of the author of this message. `name` is required if role is `function`, and it
            should be the name of the function whose response is in the `content`. May contain a-z,
            A-Z, 0-9, and underscores, with a maximum length of 64 characters.
        function_call:
          type: object
          description: The name and arguments of a function that should be called, as generated by the model.
          required:
            - name
            - arguments
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: |-
                The arguments to call the function with, as generated by the model in JSON format. Note that
                the model does not always generate valid JSON, and may hallucinate parameters not defined by
                your function schema. Validate the arguments in your code before calling your function.
    ChatCompletionResponseMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum:
            - system
            - user
            - assistant
            - function
          description: The role of the author of this message.
        content:
          type: string
          nullable: true
          description: The contents of the message.
        function_call:
          type: object
          description: The name and arguments of a function that should be called, as generated by the model.
          required:
            - name
            - arguments
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: |-
                The arguments to call the function with, as generated by the model in JSON format. Note that
                the model does not always generate valid JSON, and may hallucinate parameters not defined by
                your function schema. Validate the arguments in your code before calling your function.
    CompletionUsage:
      type: object
      description: Usage statistics for the completion request.
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      properties:
        prompt_tokens:
          type: integer
          format: int64
          description: Number of tokens in the prompt.
        completion_tokens:
          type: integer
          format: int64
          description: Number of tokens in the generated completion
        total_tokens:
          type: integer
          format: int64
          description: Total number of tokens used in the request (prompt + completion).
    CreateChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - gpt4
                - gpt-4-0314
                - gpt-4-0613
                - gpt-4-32k
                - gpt-4-32k-0314
                - gpt-4-32k-0613
                - gpt-3.5-turbo
                - gpt-3.5-turbo-16k
                - gpt-3.5-turbo-0301
                - gpt-3.5-turbo-0613
                - gpt-3.5-turbo-16k-0613
          description: |-
            ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility)
            table for details on which models work with the Chat API.
          x-oaiTypeLabel: string
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionRequestMessage'
          description: |-
            A list of messages comprising the conversation so far.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb).
          minItems: 1
        functions:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
          description: A list of functions the model may generate JSON inputs for.
          minItems: 1
          maxItems: 128
        function_call:
          anyOf:
            - type: string
              enum:
                - none
                - auto
            - $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
          description: |-
            Controls how the model responds to function calls. `none` means the model does not call a
            function, and responds to the end-user. `auto` means the model can pick between an end-user or
            calling a function.  Specifying a particular function via `{\"name":\ \"my_function\"}` forces the
            model to call that function. `none` is the default when no functions are present. `auto` is the
            default if functions are present.
        temperature:
          oneOf:
            - $ref: '#/components/schemas/Temperature'
          nullable: true
          description: |-
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
            more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
          default: 1
        top_p:
          oneOf:
            - $ref: '#/components/schemas/TopP'
          nullable: true
          description: |-
            An alternative to sampling with temperature, called nucleus sampling, where the model considers
            the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising
            the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
          default: 1
        n:
          oneOf:
            - $ref: '#/components/schemas/N'
          nullable: true
          description: |-
            How many completions to generate for each prompt.
            **Note:** Because this parameter generates many completions, it can quickly consume your token
            quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          default: 1
        max_tokens:
          oneOf:
            - $ref: '#/components/schemas/MaxTokens'
          nullable: true
          description: |-
            The maximum number of [tokens](/tokenizer) to generate in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
            for counting tokens.
          default: 16
        stop:
          allOf:
            - $ref: '#/components/schemas/Stop'
          description: Up to 4 sequences where the API will stop generating further tokens.
          default: null
        presence_penalty:
          oneOf:
            - $ref: '#/components/schemas/Penalty'
          nullable: true
          description: |-
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear
            in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
        frequency_penalty:
          oneOf:
            - $ref: '#/components/schemas/Penalty'
          nullable: true
          description: |-
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing
            frequency in the text so far, decreasing the model's likelihood to repeat the same line
            verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
        logit_bias:
          type: object
          description: |-
            Modify the likelihood of specified tokens appearing in the completion.
            Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an
            associated bias value from -100 to 100. Mathematically, the bias is added to the logits
            generated by the model prior to sampling. The exact effect will vary per model, but values
            between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100
            should result in a ban or exclusive selection of the relevant token.
          additionalProperties:
            type: integer
            format: int64
          nullable: true
          x-oaiTypeLabel: map
        user:
          allOf:
            - $ref: '#/components/schemas/User'
          description: |-
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
        stream:
          type: boolean
          nullable: true
          description: |-
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only
            [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]` message.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
          default: true
    CreateChatCompletionResponse:
      type: object
      description: Represents a chat completion response returned by model, based on the provided input.
      required:
        - id
        - object
        - created
        - model
        - choices
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        object:
          type: string
          description: The object type, which is always `chat.completion`.
        created:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        model:
          type: string
          description: The model used for the chat completion.
        choices:
          type: array
          items:
            type: object
            required:
              - index
              - message
              - finish_reason
            properties:
              index:
                type: integer
                format: int64
                description: The index of the choice in the list of choices.
              message:
                $ref: '#/components/schemas/ChatCompletionResponseMessage'
              finish_reason:
                type: string
                enum:
                  - stop
                  - length
                  - function_call
                  - content_filter
                description: |-
                  The reason the model stopped generating tokens. This will be `stop` if the model hit a
                  natural stop point or a provided stop sequence, `length` if the maximum number of tokens
                  specified in the request was reached, `content_filter` if the content was omitted due to
                  a flag from our content filters, or `function_call` if the model called a function.
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: ''
    CreateCompletionRequest:
      type: object
      required:
        - model
        - prompt
      properties:
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - babbage-002
                - davinci-002
                - text-davinci-003
                - text-davinci-002
                - text-davinci-001
                - code-davinci-002
                - text-curie-001
                - text-babbage-001
                - text-ada-001
          description: |-
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to
            see all of your available models, or see our [Model overview](/docs/models/overview) for
            descriptions of them.
          x-oaiTypeLabel: string
        prompt:
          allOf:
            - $ref: '#/components/schemas/Prompt'
          description: |-
            The prompt(s) to generate completions for, encoded as a string, array of strings, array of
            tokens, or array of token arrays.

            Note that <|endoftext|> is the document separator that the model sees during training, so if a
            prompt is not specified the model will generate as if from the beginning of a new document.
          default: <|endoftext|>
        suffix:
          type: string
          nullable: true
          description: The suffix that comes after a completion of inserted text.
          default: null
        temperature:
          oneOf:
            - $ref: '#/components/schemas/Temperature'
          nullable: true
          description: |-
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
            more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
          default: 1
        top_p:
          oneOf:
            - $ref: '#/components/schemas/TopP'
          nullable: true
          description: |-
            An alternative to sampling with temperature, called nucleus sampling, where the model considers
            the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising
            the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
          default: 1
        n:
          oneOf:
            - $ref: '#/components/schemas/N'
          nullable: true
          description: |-
            How many completions to generate for each prompt.
            **Note:** Because this parameter generates many completions, it can quickly consume your token
            quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          default: 1
        max_tokens:
          oneOf:
            - $ref: '#/components/schemas/MaxTokens'
          nullable: true
          description: |-
            The maximum number of [tokens](/tokenizer) to generate in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
            for counting tokens.
          default: 16
        stop:
          allOf:
            - $ref: '#/components/schemas/Stop'
          description: Up to 4 sequences where the API will stop generating further tokens.
          default: null
        presence_penalty:
          oneOf:
            - $ref: '#/components/schemas/Penalty'
          nullable: true
          description: |-
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear
            in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
        frequency_penalty:
          oneOf:
            - $ref: '#/components/schemas/Penalty'
          nullable: true
          description: |-
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing
            frequency in the text so far, decreasing the model's likelihood to repeat the same line
            verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/gpt/parameter-details)
        logit_bias:
          type: object
          description: |-
            Modify the likelihood of specified tokens appearing in the completion.
            Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an
            associated bias value from -100 to 100. Mathematically, the bias is added to the logits
            generated by the model prior to sampling. The exact effect will vary per model, but values
            between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100
            should result in a ban or exclusive selection of the relevant token.
          additionalProperties:
            type: integer
            format: int64
          nullable: true
          x-oaiTypeLabel: map
        user:
          allOf:
            - $ref: '#/components/schemas/User'
          description: |-
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect
            abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
        stream:
          type: boolean
          nullable: true
          description: |-
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only
            [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]` message.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb).
          default: true
        logprobs:
          type: integer
          format: int64
          nullable: true
          description: |-
            Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens.
            For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The
            API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1`
            elements in the response.

            The maximum value for `logprobs` is 5.
          default: null
        echo:
          type: boolean
          nullable: true
          description: Echo back the prompt in addition to the completion
          default: false
        best_of:
          type: integer
          format: int64
          nullable: true
          description: |-
            Generates `best_of` completions server-side and returns the "best" (the one with the highest
            log probability per token). Results cannot be streamed.

            When used with `n`, `best_of` controls the number of candidate completions and `n` specifies
            how many to return â€“ `best_of` must be greater than `n`.

            **Note:** Because this parameter generates many completions, it can quickly consume your token
            quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          default: 1
    CreateCompletionResponse:
      type: object
      description: |-
        Represents a completion response from the API. Note: both the streamed and non-streamed response
        objects share the same shape (unlike the chat endpoint).
      required:
        - id
        - object
        - created
        - model
        - choices
      properties:
        id:
          type: string
          description: A unique identifier for the completion.
        object:
          type: string
          description: The object type, which is always `text_completion`.
        created:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) of when the completion was created.
        model:
          type: string
          description: The model used for the completion.
        choices:
          type: array
          items:
            type: object
            required:
              - index
              - text
              - logprobs
              - finish_reason
            properties:
              index:
                type: integer
                format: int64
              text:
                type: string
              logprobs:
                type: object
                required:
                  - tokens
                  - token_logprobs
                  - top_logprobs
                  - text_offset
                properties:
                  tokens:
                    type: array
                    items:
                      type: string
                  token_logprobs:
                    type: array
                    items:
                      type: number
                      format: double
                  top_logprobs:
                    type: array
                    items:
                      type: object
                      additionalProperties:
                        type: integer
                        format: int64
                  text_offset:
                    type: array
                    items:
                      type: integer
                      format: int64
                nullable: true
              finish_reason:
                type: string
                enum:
                  - stop
                  - length
                  - content_filter
                description: |-
                  The reason the model stopped generating tokens. This will be `stop` if the model hit a
                  natural stop point or a provided stop sequence, or `content_filter` if content was omitted
                  due to a flag from our content filters, `length` if the maximum number of tokens specified
                  in the request was reached, or `content_filter` if content was omitted due to a flag from our
                  content filters.
          description: The list of completion choices the model generated for the input.
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      x-oaiMeta:
        name: The  completion object
        legacy: true
        example: ''
    CreateEditRequest:
      type: object
      required:
        - model
        - instruction
      properties:
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - text-davinci-edit-001
                - code-davinci-edit-001
          description: |-
            ID of the model to use. You can use the `text-davinci-edit-001` or `code-davinci-edit-001`
            model with this endpoint.
          x-oaiTypeLabel: string
        input:
          type: string
          nullable: true
          description: The input text to use as a starting point for the edit.
          default: ''
        instruction:
          type: string
          description: The instruction that tells the model how to edit the prompt.
        n:
          oneOf:
            - $ref: '#/components/schemas/EditN'
          nullable: true
          description: How many edits to generate for the input and instruction.
          default: 1
        temperature:
          oneOf:
            - $ref: '#/components/schemas/Temperature'
          nullable: true
          description: |-
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
            more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
          default: 1
        top_p:
          oneOf:
            - $ref: '#/components/schemas/TopP'
          nullable: true
          description: |-
            An alternative to sampling with temperature, called nucleus sampling, where the model considers
            the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising
            the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
          default: 1
    CreateEditResponse:
      type: object
      required:
        - object
        - created
        - choices
        - usage
      properties:
        object:
          type: string
          enum:
            - edit
          description: The object type, which is always `edit`.
        created:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) of when the edit was created.
        choices:
          type: array
          items:
            type: object
            required:
              - text
              - index
              - finish_reason
            properties:
              text:
                type: string
                description: The edited result.
              index:
                type: integer
                format: int64
                description: The index of the choice in the list of choices.
              finish_reason:
                type: string
                enum:
                  - stop
                  - length
                description: |-
                  The reason the model stopped generating tokens. This will be `stop` if the model hit a
                  natural stop point or a provided stop sequence, or `length` if the maximum number of tokens
                  specified in the request was reached.
          description: 'description: A list of edit choices. Can be more than one if `n` is greater than 1.'
        usage:
          $ref: '#/components/schemas/CompletionUsage'
    CreateEmbeddingRequest:
      type: object
      required:
        - model
        - input
      properties:
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - text-embedding-ada-002
          description: ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
          x-oaiTypeLabel: string
        input:
          anyOf:
            - type: string
            - type: array
              items:
                type: string
            - $ref: '#/components/schemas/TokenArray'
            - $ref: '#/components/schemas/TokenArrayArray'
          description: |-
            Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a
            single request, pass an array of strings or array of token arrays. Each input must not exceed
            the max input tokens for the model (8191 tokens for `text-embedding-ada-002`) and cannot be an empty string.
            [Example Python code](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)
            for counting tokens.
        user:
          $ref: '#/components/schemas/User'
    CreateEmbeddingResponse:
      type: object
      required:
        - object
        - model
        - data
        - usage
      properties:
        object:
          type: string
          enum:
            - embedding
          description: The object type, which is always "embedding".
        model:
          type: string
          description: The name of the model used to generate the embedding.
        data:
          type: array
          items:
            $ref: '#/components/schemas/Embedding'
          description: The list of embeddings generated by the model.
        usage:
          type: object
          description: The usage information for the request.
          required:
            - prompt_tokens
            - total_tokens
          properties:
            prompt_tokens:
              type: integer
              format: int64
              description: The number of tokens used by the prompt.
            total_tokens:
              type: integer
              format: int64
              description: The total number of tokens used by the request.
    CreateFileRequest:
      type: object
      required:
        - file
        - purpose
      properties:
        file:
          type: string
          format: binary
          description: |-
            Name of the [JSON Lines](https://jsonlines.readthedocs.io/en/latest/) file to be uploaded.

            If the `purpose` is set to "fine-tune", the file will be used for fine-tuning.
        purpose:
          type: string
          description: |-
            The intended purpose of the uploaded documents. Use "fine-tune" for
            [fine-tuning](/docs/api-reference/fine-tuning). This allows us to validate the format of the
            uploaded file.
    CreateFineTuneRequest:
      type: object
      required:
        - training_file
      properties:
        training_file:
          type: string
          description: |-
            The ID of an uploaded file that contains training data.

            See [upload file](/docs/api-reference/files/upload) for how to upload a file.

            Your dataset must be formatted as a JSONL file, where each training example is a JSON object
            with the keys "prompt" and "completion". Additionally, you must upload your file with the
            purpose `fine-tune`.

            See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/creating-training-data) for more
            details.
        validation_file:
          type: string
          nullable: true
          description: |-
            The ID of an uploaded file that contains validation data.

            If you provide this file, the data is used to generate validation metrics periodically during
            fine-tuning. These metrics can be viewed in the
            [fine-tuning results file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).
            Your train and validation data should be mutually exclusive.

            Your dataset must be formatted as a JSONL file, where each validation example is a JSON object
            with the keys "prompt" and "completion". Additionally, you must upload your file with the
            purpose `fine-tune`.

            See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/creating-training-data) for more
            details.
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - ada
                - babbage
                - curie
                - davinci
          nullable: true
          description: |-
            The name of the base model to fine-tune. You can select one of "ada", "babbage", "curie",
            "davinci", or a fine-tuned model created after 2022-04-21 and before 2023-08-22. To learn more
            about these models, see the [Models](/docs/models) documentation.
          x-oaiTypeLabel: string
        n_epochs:
          type: integer
          format: int64
          nullable: true
          description: |-
            The number of epochs to train the model for. An epoch refers to one full cycle through the
            training dataset.
          default: 4
        batch_size:
          type: integer
          format: int64
          nullable: true
          description: |-
            The batch size to use for training. The batch size is the number of training examples used to
            train a single forward and backward pass.

            By default, the batch size will be dynamically configured to be ~0.2% of the number of examples
            in the training set, capped at 256 - in general, we've found that larger batch sizes tend to
            work better for larger datasets.
          default: null
        learning_rate_multiplier:
          type: number
          format: double
          nullable: true
          description: |-
            The learning rate multiplier to use for training. The fine-tuning learning rate is the original
            learning rate used for pretraining multiplied by this value.

            By default, the learning rate multiplier is the 0.05, 0.1, or 0.2 depending on final
            `batch_size` (larger learning rates tend to perform better with larger batch sizes). We
            recommend experimenting with values in the range 0.02 to 0.2 to see what produces the best
            results.
          default: null
        prompt_loss_rate:
          type: number
          format: double
          nullable: true
          description: |-
            The weight to use for loss on the prompt tokens. This controls how much the model tries to
            learn to generate the prompt (as compared to the completion which always has a weight of 1.0),
            and can add a stabilizing effect to training when completions are short.

            If prompts are extremely long (relative to completions), it may make sense to reduce this
            weight so as to avoid over-prioritizing learning the prompt.
          default: 0.01
        compute_classification_metrics:
          type: boolean
          nullable: true
          description: |-
            If set, we calculate classification-specific metrics such as accuracy and F-1 score using the
            validation set at the end of every epoch. These metrics can be viewed in the
            [results file](/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).

            In order to compute classification metrics, you must provide a `validation_file`. Additionally,
            you must specify `classification_n_classes` for multiclass classification or
            `classification_positive_class` for binary classification.
          default: false
        classification_n_classes:
          type: integer
          format: int64
          nullable: true
          description: |-
            The number of classes in a classification task.

            This parameter is required for multiclass classification.
          default: null
        classification_positive_class:
          type: string
          nullable: true
          description: |-
            The positive class in binary classification.

            This parameter is needed to generate precision, recall, and F1 metrics when doing binary
            classification.
          default: null
        classification_betas:
          type: array
          items:
            type: number
            format: double
          nullable: true
          description: |-
            If this is provided, we calculate F-beta scores at the specified beta values. The F-beta score
            is a generalization of F-1 score. This is only used for binary classification.

            With a beta of 1 (i.e. the F-1 score), precision and recall are given the same weight. A larger
            beta score puts more weight on recall and less on precision. A smaller beta score puts more
            weight on precision and less on recall.
          default: null
        suffix:
          oneOf:
            - $ref: '#/components/schemas/SuffixString'
          nullable: true
          description: |-
            A string of up to 18 characters that will be added to your fine-tuned model name.

            For example, a `suffix` of "custom-model-name" would produce a model name like
            `ada:ft-your-org:custom-model-name-2022-02-15-04-21-04`.
          default: null
    CreateFineTuningJobRequest:
      type: object
      required:
        - training_file
        - model
      properties:
        training_file:
          type: string
          description: |-
            The ID of an uploaded file that contains training data.

            See [upload file](/docs/api-reference/files/upload) for how to upload a file.

            Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with
            the purpose `fine-tune`.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
        validation_file:
          type: string
          nullable: true
          description: |-
            The ID of an uploaded file that contains validation data.

            If you provide this file, the data is used to generate validation metrics periodically during
            fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should
            not be present in both train and validation files.

            Your dataset must be formatted as a JSONL file. You must upload your file with the purpose
            `fine-tune`.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - babbage-002
                - davinci-002
                - gpt-3.5-turbo
          description: |-
            The name of the model to fine-tune. You can select one of the
            [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
          x-oaiTypeLabel: string
        hyperparameters:
          type: object
          description: The hyperparameters used for the fine-tuning job.
          properties:
            n_epochs:
              anyOf:
                - type: string
                  enum:
                    - auto
                - $ref: '#/components/schemas/NEpochs'
              description: |-
                The number of epochs to train the model for. An epoch refers to one full cycle through the
                training dataset.
              default: auto
        suffix:
          oneOf:
            - $ref: '#/components/schemas/SuffixString'
          nullable: true
          description: |-
            A string of up to 18 characters that will be added to your fine-tuned model name.

            For example, a `suffix` of "custom-model-name" would produce a model name like
            `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
          default: null
    CreateImageEditRequest:
      type: object
      required:
        - prompt
        - image
      properties:
        prompt:
          type: string
          description: A text description of the desired image(s). The maximum length is 1000 characters.
        image:
          type: string
          format: binary
          description: |-
            The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not
            provided, image must have transparency, which will be used as the mask.
        mask:
          type: string
          format: binary
          description: |-
            An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where
            `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions
            as `image`.
        n:
          oneOf:
            - $ref: '#/components/schemas/ImagesN'
          nullable: true
          description: The number of images to generate. Must be between 1 and 10.
          default: 1
        size:
          type: string
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          nullable: true
          description: The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.
          default: 1024x1024
        response_format:
          type: string
          enum:
            - url
            - b64_json
          nullable: true
          description: The format in which the generated images are returned. Must be one of `url` or `b64_json`.
          default: url
        user:
          $ref: '#/components/schemas/User'
    CreateImageRequest:
      type: object
      required:
        - prompt
      properties:
        prompt:
          type: string
          description: A text description of the desired image(s). The maximum length is 1000 characters.
        n:
          oneOf:
            - $ref: '#/components/schemas/ImagesN'
          nullable: true
          description: The number of images to generate. Must be between 1 and 10.
          default: 1
        size:
          type: string
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          nullable: true
          description: The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.
          default: 1024x1024
        response_format:
          type: string
          enum:
            - url
            - b64_json
          nullable: true
          description: The format in which the generated images are returned. Must be one of `url` or `b64_json`.
          default: url
        user:
          $ref: '#/components/schemas/User'
    CreateImageVariationRequest:
      type: object
      required:
        - image
      properties:
        image:
          type: string
          format: binary
          description: |-
            The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB,
            and square.
        n:
          oneOf:
            - $ref: '#/components/schemas/ImagesN'
          nullable: true
          description: The number of images to generate. Must be between 1 and 10.
          default: 1
        size:
          type: string
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          nullable: true
          description: The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.
          default: 1024x1024
        response_format:
          type: string
          enum:
            - url
            - b64_json
          nullable: true
          description: The format in which the generated images are returned. Must be one of `url` or `b64_json`.
          default: url
        user:
          $ref: '#/components/schemas/User'
    CreateModerationRequest:
      type: object
      required:
        - input
      properties:
        input:
          anyOf:
            - type: string
            - type: array
              items:
                type: string
          description: The input text to classify
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - text-moderation-latest
                - text-moderation-stable
          description: |-
            Two content moderations models are available: `text-moderation-stable` and
            `text-moderation-latest`. The default is `text-moderation-latest` which will be automatically
            upgraded over time. This ensures you are always using our most accurate model. If you use
            `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy
            of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`.
          x-oaiTypeLabel: string
          default: text-moderation-latest
    CreateModerationResponse:
      type: object
      required:
        - id
        - model
        - results
      properties:
        id:
          type: string
          description: The unique identifier for the moderation request.
        model:
          type: string
          description: The model used to generate the moderation results.
        results:
          type: array
          items:
            type: object
            required:
              - flagged
              - categories
              - category_scores
            properties:
              flagged:
                type: boolean
                description: Whether the content violates [OpenAI's usage policies](/policies/usage-policies).
              categories:
                type: object
                description: A list of the categories, and whether they are flagged or not.
                required:
                  - hate
                  - hate/threatening
                  - harassment
                  - harassment/threatening
                  - self-harm
                  - self-harm/intent
                  - self-harm/instructive
                  - sexual
                  - sexual/minors
                  - violence
                  - violence/graphic
                properties:
                  hate:
                    type: boolean
                    description: |-
                      Content that expresses, incites, or promotes hate based on race, gender, ethnicity,
                      religion, nationality, sexual orientation, disability status, or caste. Hateful content
                      aimed at non-protected groups (e.g., chess players) is harrassment.
                  hate/threatening:
                    type: boolean
                    description: |-
                      Hateful content that also includes violence or serious harm towards the targeted group
                      based on race, gender, ethnicity, religion, nationality, sexual orientation, disability
                      status, or caste.
                  harassment:
                    type: boolean
                    description: Content that expresses, incites, or promotes harassing language towards any target.
                  harassment/threatening:
                    type: boolean
                    description: Harassment content that also includes violence or serious harm towards any target.
                  self-harm:
                    type: boolean
                    description: |-
                      Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting,
                      and eating disorders.
                  self-harm/intent:
                    type: boolean
                    description: |-
                      Content where the speaker expresses that they are engaging or intend to engage in acts of
                      self-harm, such as suicide, cutting, and eating disorders.
                  self-harm/instructive:
                    type: boolean
                    description: |-
                      Content that encourages performing acts of self-harm, such as suicide, cutting, and eating
                      disorders, or that gives instructions or advice on how to commit such acts.
                  sexual:
                    type: boolean
                    description: |-
                      Content meant to arouse sexual excitement, such as the description of sexual activity, or
                      that promotes sexual services (excluding sex education and wellness).
                  sexual/minors:
                    type: boolean
                    description: Sexual content that includes an individual who is under 18 years old.
                  violence:
                    type: boolean
                    description: Content that depicts death, violence, or physical injury.
                  violence/graphic:
                    type: boolean
                    description: Content that depicts death, violence, or physical injury in graphic detail.
              category_scores:
                type: object
                description: A list of the categories along with their scores as predicted by model.
                required:
                  - hate
                  - hate/threatening
                  - harassment
                  - harassment/threatening
                  - self-harm
                  - self-harm/intent
                  - self-harm/instructive
                  - sexual
                  - sexual/minors
                  - violence
                  - violence/graphic
                properties:
                  hate:
                    type: number
                    format: double
                    description: The score for the category 'hate'.
                  hate/threatening:
                    type: number
                    format: double
                    description: The score for the category 'hate/threatening'.
                  harassment:
                    type: number
                    format: double
                    description: The score for the category 'harassment'.
                  harassment/threatening:
                    type: number
                    format: double
                    description: The score for the category 'harassment/threatening'.
                  self-harm:
                    type: number
                    format: double
                    description: The score for the category 'self-harm'.
                  self-harm/intent:
                    type: number
                    format: double
                    description: The score for the category 'self-harm/intent'.
                  self-harm/instructive:
                    type: number
                    format: double
                    description: The score for the category 'self-harm/instructive'.
                  sexual:
                    type: number
                    format: double
                    description: The score for the category 'sexual'.
                  sexual/minors:
                    type: number
                    format: double
                    description: The score for the category 'sexual/minors'.
                  violence:
                    type: number
                    format: double
                    description: The score for the category 'violence'.
                  violence/graphic:
                    type: number
                    format: double
                    description: The score for the category 'violence/graphic'.
          description: A list of moderation objects.
    CreateTranscriptionRequest:
      type: object
      required:
        - file
        - model
      properties:
        file:
          type: string
          format: binary
          description: |-
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
          x-oaiTypeLabel: file
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - whisper-1
          description: ID of the model to use. Only `whisper-1` is currently available.
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: |-
            An optional text to guide the model's style or continue a previous audio segment. The
            [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
        response_format:
          type: string
          enum:
            - json
            - text
            - srt
            - verbose_json
            - vtt
          description: |-
            The format of the transcript output, in one of these options: json, text, srt, verbose_json, or
            vtt.
          default: json
        temperature:
          type: number
          format: double
          description: |-
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more
            random, while lower values like 0.2 will make it more focused and deterministic. If set to 0,
            the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to
            automatically increase the temperature until certain thresholds are hit.
          minimum: 0
          maximum: 1
          default: 0
        language:
          type: string
          description: |-
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy
            and latency.
    CreateTranscriptionResponse:
      type: object
      required:
        - text
      properties:
        text:
          type: string
    CreateTranslationRequest:
      type: object
      required:
        - file
        - model
      properties:
        file:
          type: string
          format: binary
          description: |-
            The audio file object (not file name) to translate, in one of these formats: flac, mp3, mp4,
            mpeg, mpga, m4a, ogg, wav, or webm.
          x-oaiTypeLabel: file
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - whisper-1
          description: ID of the model to use. Only `whisper-1` is currently available.
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: |-
            An optional text to guide the model's style or continue a previous audio segment. The
            [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
        response_format:
          type: string
          enum:
            - json
            - text
            - srt
            - verbose_json
            - vtt
          description: |-
            The format of the transcript output, in one of these options: json, text, srt, verbose_json, or
            vtt.
          default: json
        temperature:
          type: number
          format: double
          description: |-
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more
            random, while lower values like 0.2 will make it more focused and deterministic. If set to 0,
            the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to
            automatically increase the temperature until certain thresholds are hit.
          minimum: 0
          maximum: 1
          default: 0
    CreateTranslationResponse:
      type: object
      required:
        - text
      properties:
        text:
          type: string
    DeleteFileResponse:
      type: object
      required:
        - id
        - object
        - deleted
      properties:
        id:
          type: string
        object:
          type: string
        deleted:
          type: boolean
    DeleteModelResponse:
      type: object
      required:
        - id
        - object
        - deleted
      properties:
        id:
          type: string
        object:
          type: string
        deleted:
          type: boolean
    EditN:
      type: integer
      format: int64
      minimum: 0
      maximum: 20
    Embedding:
      type: object
      description: Represents an embedding vector returned by embedding endpoint.
      required:
        - index
        - object
        - embedding
      properties:
        index:
          type: integer
          format: int64
          description: The index of the embedding in the list of embeddings.
        object:
          type: string
          enum:
            - embedding
          description: The object type, which is always "embedding".
        embedding:
          type: array
          items:
            type: number
            format: double
          description: |-
            The embedding vector, which is a list of floats. The length of vector depends on the model as\
            listed in the [embedding guide](/docs/guides/embeddings).
    Error:
      type: object
      required:
        - type
        - message
        - param
        - code
      properties:
        type:
          type: string
        message:
          type: string
        param:
          type: string
          nullable: true
        code:
          type: string
          nullable: true
    ErrorResponse:
      type: object
      required:
        - error
      properties:
        error:
          $ref: '#/components/schemas/Error'
    FineTune:
      type: object
      description: The `FineTune` object represents a legacy fine-tune job that has been created through the API.
      required:
        - id
        - object
        - created_at
        - updated_at
        - model
        - fine_tuned_model
        - organization_id
        - status
        - hyperparams
        - training_files
        - validation_files
        - result_files
      properties:
        id:
          type: string
          description: The object identifier, which can be referenced in the API endpoints.
        object:
          type: string
          enum:
            - fine-tune
          description: The object type, which is always "fine-tune".
        created_at:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) for when the fine-tuning job was created.
        updated_at:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) for when the fine-tuning job was last updated.
        model:
          type: string
          description: The base model that is being fine-tuned.
        fine_tuned_model:
          type: string
          nullable: true
          description: The name of the fine-tuned model that is being created.
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job.
        status:
          type: string
          enum:
            - created
            - running
            - succeeded
            - failed
            - cancelled
          description: |-
            The current status of the fine-tuning job, which can be either `created`, `running`,
            `succeeded`, `failed`, or `cancelled`.
        hyperparams:
          type: object
          description: |-
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/legacy-fine-tuning/hyperparameters) for more details.
          required:
            - n_epochs
            - batch_size
            - prompt_loss_weight
            - learning_rate_multiplier
          properties:
            n_epochs:
              type: integer
              format: int64
              description: |-
                The number of epochs to train the model for. An epoch refers to one full cycle through the
                training dataset.
            batch_size:
              type: integer
              format: int64
              description: |-
                The batch size to use for training. The batch size is the number of training examples used to
                train a single forward and backward pass.
            prompt_loss_weight:
              type: number
              format: double
              description: The weight to use for loss on the prompt tokens.
            learning_rate_multiplier:
              type: number
              format: double
              description: The learning rate multiplier to use for training.
            compute_classification_metrics:
              type: boolean
              description: The classification metrics to compute using the validation dataset at the end of every epoch.
            classification_positive_class:
              type: string
              description: The positive class to use for computing classification metrics.
            classification_n_classes:
              type: integer
              format: int64
              description: The number of classes to use for computing classification metrics.
        training_files:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
          description: The list of files used for training.
        validation_files:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
          description: The list of files used for validation.
        result_files:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
          description: The compiled results files for the fine-tuning job.
        events:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
          description: The list of events that have been observed in the lifecycle of the FineTune job.
    FineTuneEvent:
      type: object
      required:
        - object
        - created_at
        - level
        - message
      properties:
        object:
          type: string
        created_at:
          type: integer
          format: unixtime
        level:
          type: string
        message:
          type: string
    FineTuningEvent:
      type: object
      required:
        - object
        - created_at
        - level
        - message
      properties:
        object:
          type: string
        created_at:
          type: integer
          format: unixtime
        level:
          type: string
        message:
          type: string
        data:
          type: object
          additionalProperties: {}
          nullable: true
        type:
          type: string
          enum:
            - message
            - metrics
    FineTuningJob:
      type: object
      required:
        - id
        - object
        - created_at
        - finished_at
        - model
        - fine_tuned_model
        - organization_id
        - status
        - hyperparameters
        - training_file
        - validation_file
        - result_files
        - trained_tokens
        - error
      properties:
        id:
          type: string
          description: The object identifier, which can be referenced in the API endpoints.
        object:
          type: string
          enum:
            - fine_tuning.job
          description: The object type, which is always "fine_tuning.job".
        created_at:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) for when the fine-tuning job was created.
        finished_at:
          type: string
          format: date-time
          nullable: true
          description: |-
            The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be
            null if the fine-tuning job is still running.
        model:
          type: string
          description: The base model that is being fine-tuned.
        fine_tuned_model:
          type: string
          nullable: true
          description: |-
            The name of the fine-tuned model that is being created. The value will be null if the
            fine-tuning job is still running.
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job.
        status:
          type: string
          enum:
            - created
            - pending
            - running
            - succeeded
            - failed
            - cancelled
          description: |-
            The current status of the fine-tuning job, which can be either `created`, `pending`, `running`,
            `succeeded`, `failed`, or `cancelled`.
        hyperparameters:
          type: object
          description: |-
            The hyperparameters used for the fine-tuning job. See the
            [fine-tuning guide](/docs/guides/fine-tuning) for more details.
          properties:
            n_epochs:
              anyOf:
                - type: string
                  enum:
                    - auto
                - $ref: '#/components/schemas/NEpochs'
              description: |-
                The number of epochs to train the model for. An epoch refers to one full cycle through the
                training dataset.

                "Auto" decides the optimal number of epochs based on the size of the dataset. If setting the
                number manually, we support any number between 1 and 50 epochs.
              default: auto
        training_file:
          type: string
          description: |-
            The file ID used for training. You can retrieve the training data with the
            [Files API](/docs/api-reference/files/retrieve-contents).
        validation_file:
          type: string
          nullable: true
          description: |-
            The file ID used for validation. You can retrieve the validation results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
        result_files:
          type: array
          items:
            type: string
          description: |-
            The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the
            [Files API](/docs/api-reference/files/retrieve-contents).
        trained_tokens:
          type: integer
          format: int64
          nullable: true
          description: |-
            The total number of billable tokens processed by this fine tuning job. The value will be null
            if the fine-tuning job is still running.
        error:
          type: object
          description: |-
            For fine-tuning jobs that have `failed`, this will contain more information on the cause of the
            failure.
          properties:
            message:
              type: string
              description: A human-readable error message.
            code:
              type: string
              description: A machine-readable error code.
            param:
              type: string
              nullable: true
              description: |-
                The parameter that was invalid, usually `training_file` or `validation_file`. This field
                will be null if the failure was not parameter-specific.
          nullable: true
    FineTuningJobEvent:
      type: object
      required:
        - id
        - object
        - created_at
        - level
        - message
      properties:
        id:
          type: string
        object:
          type: string
        created_at:
          type: integer
          format: unixtime
        level:
          type: string
          enum:
            - info
            - warn
            - error
        message:
          type: string
    Image:
      type: object
      description: Represents the url or the content of an image generated by the OpenAI API.
      properties:
        url:
          type: string
          format: uri
          description: The URL of the generated image, if `response_format` is `url` (default).
        b64_json:
          type: string
          format: base64
          description: The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.
    ImagesN:
      type: integer
      format: int64
      minimum: 1
      maximum: 10
    ImagesResponse:
      type: object
      required:
        - created
        - data
      properties:
        created:
          type: integer
          format: unixtime
        data:
          type: array
          items:
            $ref: '#/components/schemas/Image'
    ListFilesResponse:
      type: object
      required:
        - object
        - data
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
    ListFineTuneEventsResponse:
      type: object
      required:
        - object
        - data
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
    ListFineTunesResponse:
      type: object
      required:
        - object
        - data
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTune'
    ListFineTuningJobEventsResponse:
      type: object
      required:
        - object
        - data
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobEvent'
    ListModelsResponse:
      type: object
      required:
        - object
        - data
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
    ListPaginatedFineTuningJobsResponse:
      type: object
      required:
        - object
        - data
        - has_more
      properties:
        object:
          type: string
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJob'
        has_more:
          type: boolean
    MaxTokens:
      type: integer
      format: int64
      minimum: 0
    Model:
      type: object
      description: Describes an OpenAI model offering that can be used with the API.
      required:
        - id
        - object
        - created
        - owned_by
      properties:
        id:
          type: string
          description: The model identifier, which can be referenced in the API endpoints.
        object:
          type: string
          enum:
            - model
          description: The object type, which is always "model".
        created:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) when the model was created.
        owned_by:
          type: string
          description: The organization that owns the model.
    N:
      type: integer
      format: int64
      minimum: 1
      maximum: 128
    NEpochs:
      type: integer
      format: int64
      minimum: 1
      maximum: 50
    OpenAIFile:
      type: object
      description: The `File` object represents a document that has been uploaded to OpenAI.
      required:
        - id
        - object
        - bytes
        - createdAt
        - filename
        - purpose
        - status
      properties:
        id:
          type: string
          description: The file identifier, which can be referenced in the API endpoints.
        object:
          type: string
          enum:
            - file
          description: The object type, which is always "file".
        bytes:
          type: integer
          format: int64
          description: The size of the file in bytes.
        createdAt:
          type: integer
          format: unixtime
          description: The Unix timestamp (in seconds) for when the file was created.
        filename:
          type: string
          description: The name of the file.
        purpose:
          type: string
          description: The intended purpose of the file. Currently, only "fine-tune" is supported.
        status:
          type: string
          enum:
            - uploaded
            - processed
            - pending
            - error
            - deleting
            - deleted
          description: |-
            The current status of the file, which can be either `uploaded`, `processed`, `pending`,
            `error`, `deleting` or `deleted`.
        status_details:
          type: string
          nullable: true
          description: |-
            Additional details about the status of the file. If the file is in the `error` state, this will
            include a message describing the error.
    Penalty:
      type: number
      format: double
      minimum: -2
      maximum: 2
    Prompt:
      oneOf:
        - type: string
        - type: array
          items:
            type: string
        - $ref: '#/components/schemas/TokenArray'
        - $ref: '#/components/schemas/TokenArrayArray'
      nullable: true
    Stop:
      oneOf:
        - type: string
        - $ref: '#/components/schemas/StopSequences'
      nullable: true
    StopSequences:
      type: array
      items:
        type: string
      minItems: 1
      maxItems: 4
    SuffixString:
      type: string
      minLength: 1
      maxLength: 40
    Temperature:
      type: number
      format: double
      minimum: 0
      maximum: 2
    TokenArray:
      type: array
      items:
        type: integer
        format: int64
      minItems: 1
    TokenArrayArray:
      type: array
      items:
        $ref: '#/components/schemas/TokenArray'
      minItems: 1
    TopP:
      type: number
      format: double
      minimum: 0
      maximum: 1
    User:
      type: string
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
servers:
  - url: https://api.openai.com/v1
    description: OpenAI Endpoint
    variables: {}
