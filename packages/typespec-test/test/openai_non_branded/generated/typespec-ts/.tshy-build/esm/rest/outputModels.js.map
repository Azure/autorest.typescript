{"version":3,"file":"outputModels.js","sourceRoot":"","sources":["../../../src/rest/outputModels.ts"],"names":[],"mappings":"AAAA,kCAAkC","sourcesContent":["// Licensed under the MIT license.\n\nexport interface CreateTranscriptionResponseOutput {\n  text: string;\n}\n\nexport interface ErrorResponseOutput {\n  error: ErrorModelOutput;\n}\n\nexport interface ErrorModelOutput {\n  type: string;\n  message: string;\n  param: string | null;\n  code: string | null;\n}\n\nexport interface CreateTranslationResponseOutput {\n  text: string;\n}\n\n/** Represents a chat completion response returned by model, based on the provided input. */\nexport interface CreateChatCompletionResponseOutput {\n  /** A unique identifier for the chat completion. */\n  id: string;\n  /** The object type, which is always `chat.completion`. */\n  object: string;\n  /** The Unix timestamp (in seconds) of when the chat completion was created. */\n  created: number;\n  /** The model used for the chat completion. */\n  model: string;\n  /** A list of chat completion choices. Can be more than one if `n` is greater than 1. */\n  choices: {\n    index: number;\n    message: ChatCompletionResponseMessageOutput;\n    finish_reason: \"stop\" | \"length\" | \"function_call\" | \"content_filter\";\n  }[];\n  usage?: CompletionUsageOutput;\n}\n\nexport interface ChatCompletionResponseMessageOutput {\n  /** The role of the author of this message. */\n  role: \"system\" | \"user\" | \"assistant\" | \"function\";\n  /** The contents of the message. */\n  content: string | null;\n  /** The name and arguments of a function that should be called, as generated by the model. */\n  function_call?: { name: string; arguments: string };\n}\n\n/** Usage statistics for the completion request. */\nexport interface CompletionUsageOutput {\n  /** Number of tokens in the prompt. */\n  prompt_tokens: number;\n  /** Number of tokens in the generated completion */\n  completion_tokens: number;\n  /** Total number of tokens used in the request (prompt + completion). */\n  total_tokens: number;\n}\n\nexport interface FineTuningJobOutput {\n  /** The object identifier, which can be referenced in the API endpoints. */\n  id: string;\n  /** The object type, which is always \"fine_tuning.job\". */\n  object: \"fine_tuning.job\";\n  /** The Unix timestamp (in seconds) for when the fine-tuning job was created. */\n  created_at: number;\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be\n   * null if the fine-tuning job is still running.\n   */\n  finished_at: string | null;\n  /** The base model that is being fine-tuned. */\n  model: string;\n  /**\n   * The name of the fine-tuned model that is being created. The value will be null if the\n   * fine-tuning job is still running.\n   */\n  fine_tuned_model: string | null;\n  /** The organization that owns the fine-tuning job. */\n  organization_id: string;\n  /**\n   * The current status of the fine-tuning job, which can be either `created`, `pending`, `running`,\n   * `succeeded`, `failed`, or `cancelled`.\n   */\n  status:\n    | \"created\"\n    | \"pending\"\n    | \"running\"\n    | \"succeeded\"\n    | \"failed\"\n    | \"cancelled\";\n  /**\n   * The hyperparameters used for the fine-tuning job. See the\n   * [fine-tuning guide](/docs/guides/fine-tuning) for more details.\n   */\n  hyperparameters: { n_epochs?: \"auto\" | number };\n  /**\n   * The file ID used for training. You can retrieve the training data with the\n   * [Files API](/docs/api-reference/files/retrieve-contents).\n   */\n  training_file: string;\n  /**\n   * The file ID used for validation. You can retrieve the validation results with the\n   * [Files API](/docs/api-reference/files/retrieve-contents).\n   */\n  validation_file: string | null;\n  /**\n   * The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the\n   * [Files API](/docs/api-reference/files/retrieve-contents).\n   */\n  result_files: string[];\n  /**\n   * The total number of billable tokens processed by this fine tuning job. The value will be null\n   * if the fine-tuning job is still running.\n   */\n  trained_tokens: number | null;\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on the cause of the\n   * failure.\n   */\n  error: { message?: string; code?: string; param?: string | null } | null;\n}\n\nexport interface ListPaginatedFineTuningJobsResponseOutput {\n  object: string;\n  data: Array<FineTuningJobOutput>;\n  has_more: boolean;\n}\n\nexport interface ListFineTuningJobEventsResponseOutput {\n  object: string;\n  data: Array<FineTuningJobEventOutput>;\n}\n\nexport interface FineTuningJobEventOutput {\n  id: string;\n  object: string;\n  created_at: number;\n  level: \"info\" | \"warn\" | \"error\";\n  message: string;\n}\n\n/**\n * Represents a completion response from the API. Note: both the streamed and non-streamed response\n * objects share the same shape (unlike the chat endpoint).\n */\nexport interface CreateCompletionResponseOutput {\n  /** A unique identifier for the completion. */\n  id: string;\n  /** The object type, which is always `text_completion`. */\n  object: string;\n  /** The Unix timestamp (in seconds) of when the completion was created. */\n  created: number;\n  /** The model used for the completion. */\n  model: string;\n  /** The list of completion choices the model generated for the input. */\n  choices: {\n    index: number;\n    text: string;\n    logprobs: null | {\n      tokens: string[];\n      token_logprobs: number[];\n      top_logprobs: Record<string, number>[];\n      text_offset: number[];\n    };\n    finish_reason: \"stop\" | \"length\" | \"content_filter\";\n  }[];\n  usage?: CompletionUsageOutput;\n}\n\nexport interface CreateEditResponseOutput {\n  /** The object type, which is always `edit`. */\n  object: \"edit\";\n  /** The Unix timestamp (in seconds) of when the edit was created. */\n  created: number;\n  /** description: A list of edit choices. Can be more than one if `n` is greater than 1. */\n  choices: { text: string; index: number; finish_reason: \"stop\" | \"length\" }[];\n  usage: CompletionUsageOutput;\n}\n\nexport interface CreateEmbeddingResponseOutput {\n  /** The object type, which is always \"embedding\". */\n  object: \"embedding\";\n  /** The name of the model used to generate the embedding. */\n  model: string;\n  /** The list of embeddings generated by the model. */\n  data: Array<EmbeddingOutput>;\n  /** The usage information for the request. */\n  usage: { prompt_tokens: number; total_tokens: number };\n}\n\n/** Represents an embedding vector returned by embedding endpoint. */\nexport interface EmbeddingOutput {\n  /** The index of the embedding in the list of embeddings. */\n  index: number;\n  /** The object type, which is always \"embedding\". */\n  object: \"embedding\";\n  /**\n   * The embedding vector, which is a list of floats. The length of vector depends on the model as\\\n   * listed in the [embedding guide](/docs/guides/embeddings).\n   */\n  embedding: number[];\n}\n\nexport interface ListFilesResponseOutput {\n  object: string;\n  data: Array<OpenAIFileOutput>;\n}\n\n/** The `File` object represents a document that has been uploaded to OpenAI. */\nexport interface OpenAIFileOutput {\n  /** The file identifier, which can be referenced in the API endpoints. */\n  id: string;\n  /** The object type, which is always \"file\". */\n  object: \"file\";\n  /** The size of the file in bytes. */\n  bytes: number;\n  /** The Unix timestamp (in seconds) for when the file was created. */\n  createdAt: number;\n  /** The name of the file. */\n  filename: string;\n  /** The intended purpose of the file. Currently, only \"fine-tune\" is supported. */\n  purpose: string;\n  /**\n   * The current status of the file, which can be either `uploaded`, `processed`, `pending`,\n   * `error`, `deleting` or `deleted`.\n   */\n  status:\n    | \"uploaded\"\n    | \"processed\"\n    | \"pending\"\n    | \"error\"\n    | \"deleting\"\n    | \"deleted\";\n  /**\n   * Additional details about the status of the file. If the file is in the `error` state, this will\n   * include a message describing the error.\n   */\n  status_details?: string | null;\n}\n\nexport interface DeleteFileResponseOutput {\n  id: string;\n  object: string;\n  deleted: boolean;\n}\n\n/** The `FineTune` object represents a legacy fine-tune job that has been created through the API. */\nexport interface FineTuneOutput {\n  /** The object identifier, which can be referenced in the API endpoints. */\n  id: string;\n  /** The object type, which is always \"fine-tune\". */\n  object: \"fine-tune\";\n  /** The Unix timestamp (in seconds) for when the fine-tuning job was created. */\n  created_at: number;\n  /** The Unix timestamp (in seconds) for when the fine-tuning job was last updated. */\n  updated_at: number;\n  /** The base model that is being fine-tuned. */\n  model: string;\n  /** The name of the fine-tuned model that is being created. */\n  fine_tuned_model: string | null;\n  /** The organization that owns the fine-tuning job. */\n  organization_id: string;\n  /**\n   * The current status of the fine-tuning job, which can be either `created`, `running`,\n   * `succeeded`, `failed`, or `cancelled`.\n   */\n  status: \"created\" | \"running\" | \"succeeded\" | \"failed\" | \"cancelled\";\n  /**\n   * The hyperparameters used for the fine-tuning job. See the\n   * [fine-tuning guide](/docs/guides/legacy-fine-tuning/hyperparameters) for more details.\n   */\n  hyperparams: {\n    n_epochs: number;\n    batch_size: number;\n    prompt_loss_weight: number;\n    learning_rate_multiplier: number;\n    compute_classification_metrics?: boolean;\n    classification_positive_class?: string;\n    classification_n_classes?: number;\n  };\n  /** The list of files used for training. */\n  training_files: Array<OpenAIFileOutput>;\n  /** The list of files used for validation. */\n  validation_files: Array<OpenAIFileOutput>;\n  /** The compiled results files for the fine-tuning job. */\n  result_files: Array<OpenAIFileOutput>;\n  /** The list of events that have been observed in the lifecycle of the FineTune job. */\n  events?: Array<FineTuneEventOutput>;\n}\n\nexport interface FineTuneEventOutput {\n  object: string;\n  created_at: number;\n  level: string;\n  message: string;\n}\n\nexport interface ListFineTunesResponseOutput {\n  object: string;\n  data: Array<FineTuneOutput>;\n}\n\nexport interface ListFineTuneEventsResponseOutput {\n  object: string;\n  data: Array<FineTuneEventOutput>;\n}\n\nexport interface ListModelsResponseOutput {\n  object: string;\n  data: Array<ModelOutput>;\n}\n\n/** Describes an OpenAI model offering that can be used with the API. */\nexport interface ModelOutput {\n  /** The model identifier, which can be referenced in the API endpoints. */\n  id: string;\n  /** The object type, which is always \"model\". */\n  object: \"model\";\n  /** The Unix timestamp (in seconds) when the model was created. */\n  created: number;\n  /** The organization that owns the model. */\n  owned_by: string;\n}\n\nexport interface DeleteModelResponseOutput {\n  id: string;\n  object: string;\n  deleted: boolean;\n}\n\nexport interface ImagesResponseOutput {\n  created: number;\n  data: Array<ImageOutput>;\n}\n\n/** Represents the url or the content of an image generated by the OpenAI API. */\nexport interface ImageOutput {\n  /** The URL of the generated image, if `response_format` is `url` (default). */\n  url?: string;\n  /** The base64-encoded JSON of the generated image, if `response_format` is `b64_json`. */\n  b64_json?: string;\n}\n\nexport interface CreateModerationResponseOutput {\n  /** The unique identifier for the moderation request. */\n  id: string;\n  /** The model used to generate the moderation results. */\n  model: string;\n  /** A list of moderation objects. */\n  results: {\n    flagged: boolean;\n    categories: {\n      hate: boolean;\n      \"hate/threatening\": boolean;\n      harassment: boolean;\n      \"harassment/threatening\": boolean;\n      \"self-harm\": boolean;\n      \"self-harm/intent\": boolean;\n      \"self-harm/instructive\": boolean;\n      sexual: boolean;\n      \"sexual/minors\": boolean;\n      violence: boolean;\n      \"violence/graphic\": boolean;\n    };\n    category_scores: {\n      hate: number;\n      \"hate/threatening\": number;\n      harassment: number;\n      \"harassment/threatening\": number;\n      \"self-harm\": number;\n      \"self-harm/intent\": number;\n      \"self-harm/instructive\": number;\n      sexual: number;\n      \"sexual/minors\": number;\n      violence: number;\n      \"violence/graphic\": number;\n    };\n  }[];\n}\n"]}