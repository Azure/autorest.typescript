{
  "swagger": "2.0",
  "info": {
    "title": "Azure OpenAI API",
    "version": "2022-12-01",
    "description": "Azure OpenAI APIs for completions and search",
    "x-typespec-generated": [
      {
        "emitter": "@azure-tools/typespec-autorest"
      }
    ]
  },
  "schemes": [
    "https"
  ],
  "x-ms-parameterized-host": {
    "hostTemplate": "{endpoint}/openai",
    "useSchemePrefix": false,
    "parameters": [
      {
        "name": "endpoint",
        "in": "path",
        "description": "Supported Cognitive Services endpoints (protocol and hostname, for example:\nhttps://westus.api.cognitive.microsoft.com).",
        "required": true,
        "type": "string"
      }
    ]
  },
  "produces": [
    "application/json"
  ],
  "consumes": [
    "application/json"
  ],
  "security": [
    {
      "ApiKeyAuth": []
    },
    {
      "OAuth2Auth": [
        "https://cognitiveservices.azure.com/.default"
      ]
    }
  ],
  "securityDefinitions": {
    "ApiKeyAuth": {
      "type": "apiKey",
      "name": "api-key",
      "in": "header"
    },
    "OAuth2Auth": {
      "type": "oauth2",
      "flow": "implicit",
      "authorizationUrl": "https://login.microsoftonline.com/common/oauth2/v2.0/authorize",
      "scopes": {
        "https://cognitiveservices.azure.com/.default": ""
      }
    }
  },
  "tags": [],
  "paths": {
    "/deployments/{deploymentId}/completions": {
      "post": {
        "operationId": "GetCompletions",
        "description": "Return the completions for a given prompt.",
        "parameters": [
          {
            "$ref": "#/parameters/Azure.Core.Foundations.ApiVersionParameter"
          },
          {
            "name": "deploymentId",
            "in": "path",
            "description": "deployment id of the deployed model",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/Completions.CompletionsOptions"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/Completions.Completions"
            },
            "headers": {
              "apim-request-id": {
                "type": "string",
                "description": "Request ID for troubleshooting purposes"
              }
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-convenient-api": true
      }
    },
    "/deployments/{deploymentId}/embeddings": {
      "post": {
        "operationId": "GetEmbeddings",
        "description": "Return the embeddings for a given prompt.",
        "parameters": [
          {
            "$ref": "#/parameters/Azure.Core.Foundations.ApiVersionParameter"
          },
          {
            "name": "deploymentId",
            "in": "path",
            "description": "deployment id of the deployed model",
            "required": true,
            "type": "string"
          },
          {
            "name": "body",
            "in": "body",
            "required": true,
            "schema": {
              "$ref": "#/definitions/Embeddings.EmbeddingsOptions"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "The request has succeeded.",
            "schema": {
              "$ref": "#/definitions/Embeddings.Embeddings"
            }
          },
          "default": {
            "description": "An unexpected error response.",
            "schema": {
              "$ref": "#/definitions/Azure.Core.Foundations.ErrorResponse"
            },
            "headers": {
              "x-ms-error-code": {
                "type": "string",
                "description": "String error code indicating what went wrong."
              }
            }
          }
        },
        "x-ms-convenient-api": true
      }
    }
  },
  "definitions": {
    "Azure.Core.Foundations.Error": {
      "type": "object",
      "description": "The error object.",
      "properties": {
        "code": {
          "type": "string",
          "description": "One of a server-defined set of error codes."
        },
        "message": {
          "type": "string",
          "description": "A human-readable representation of the error."
        },
        "target": {
          "type": "string",
          "description": "The target of the error."
        },
        "details": {
          "type": "array",
          "description": "An array of details about specific errors that led to this reported error.",
          "items": {
            "$ref": "#/definitions/Azure.Core.Foundations.Error"
          },
          "x-ms-identifiers": []
        },
        "innererror": {
          "$ref": "#/definitions/Azure.Core.Foundations.InnerError",
          "description": "An object containing more specific information than the current object about the error."
        }
      },
      "required": [
        "code",
        "message"
      ]
    },
    "Azure.Core.Foundations.ErrorResponse": {
      "type": "object",
      "description": "A response containing error details.",
      "properties": {
        "error": {
          "$ref": "#/definitions/Azure.Core.Foundations.Error",
          "description": "The error object."
        }
      },
      "required": [
        "error"
      ]
    },
    "Azure.Core.Foundations.InnerError": {
      "type": "object",
      "description": "An object containing more specific information about the error. As per Microsoft One API guidelines - https://github.com/Microsoft/api-guidelines/blob/vNext/Guidelines.md#7102-error-condition-responses.",
      "properties": {
        "code": {
          "type": "string",
          "description": "One of a server-defined set of error codes."
        },
        "innererror": {
          "$ref": "#/definitions/Azure.Core.Foundations.InnerError",
          "description": "Inner error."
        }
      }
    },
    "Completions.Choice": {
      "type": "object",
      "description": "Choice model within completion response",
      "properties": {
        "text": {
          "type": "string",
          "description": "Generated text for given completion prompt"
        },
        "index": {
          "type": "integer",
          "format": "int32",
          "description": "Index"
        },
        "logprobs": {
          "$ref": "#/definitions/Completions.CompletionsLogProbs",
          "description": "Log Prob Model"
        },
        "finish_reason": {
          "type": "string",
          "description": "Reason for finishing"
        }
      }
    },
    "Completions.Completions": {
      "type": "object",
      "description": "Expected response schema to completion request",
      "properties": {
        "id": {
          "type": "string",
          "description": "Id for completion response"
        },
        "object": {
          "type": "string",
          "description": "Object for completion response",
          "enum": [
            "text_completion"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "created": {
          "type": "integer",
          "format": "int32",
          "description": "Created time for completion response"
        },
        "model": {
          "type": "string",
          "description": "Model used for completion response"
        },
        "choices": {
          "type": "array",
          "description": "Array of choices returned containing text completions to prompts sent",
          "items": {
            "$ref": "#/definitions/Completions.Choice"
          },
          "x-ms-identifiers": []
        },
        "usage": {
          "$ref": "#/definitions/Completions.CompletionsUsage",
          "description": "Usage counts for tokens input using the completions API"
        }
      },
      "required": [
        "object",
        "usage"
      ]
    },
    "Completions.CompletionsLogProbs": {
      "type": "object",
      "description": "LogProbs model within completion choice",
      "properties": {
        "tokens": {
          "type": "array",
          "description": "Tokens",
          "items": {
            "type": "string"
          }
        },
        "token_logprobs": {
          "type": "array",
          "description": "LogProbs of Tokens",
          "items": {
            "type": "number",
            "format": "float"
          }
        },
        "top_logprobs": {
          "type": "array",
          "description": "Top LogProbs",
          "items": {
            "type": "object",
            "additionalProperties": {
              "format": "float",
              "type": "number"
            }
          },
          "x-ms-identifiers": []
        },
        "text_offset": {
          "type": "array",
          "description": "Text offset",
          "items": {
            "type": "integer",
            "format": "int32"
          }
        }
      }
    },
    "Completions.CompletionsOptions": {
      "type": "object",
      "description": "Post body schema to create a prompt completion from a deployment",
      "properties": {
        "prompt": {
          "type": "array",
          "description": "An optional prompt to complete from, encoded as a string, a list of strings, or\na list of token lists. Defaults to <|endoftext|>. The prompt to complete from.\nIf you would like to provide multiple prompts, use the POST variant of this\nmethod. Note that <|endoftext|> is the document separator that the model sees\nduring training, so if a prompt is not specified the model will generate as if\nfrom the beginning of a new document. Maximum allowed size of string list is\n2048.",
          "items": {
            "type": "string"
          }
        },
        "max_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "The maximum number of tokens to generate. Has minimum of 0."
        },
        "temperature": {
          "type": "number",
          "format": "float",
          "description": "What sampling temperature to use. Higher values means the model will take more\nrisks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones\nwith a well-defined answer.\nWe generally recommend using this or `top_p` but\nnot both.\nMinimum of 0 and maximum of 2 allowed.\n"
        },
        "top_p": {
          "type": "number",
          "format": "float",
          "description": "An alternative to sampling with temperature, called nucleus sampling, where the\nmodel considers the results of the tokens with top_p probability mass. So 0.1\nmeans only the tokens comprising the top 10% probability mass are\nconsidered.\nWe generally recommend using this or `temperature` but not\nboth.\nMinimum of 0 and maximum of 1 allowed.\n"
        },
        "logit_bias": {
          "type": "object",
          "description": "Defaults to null. Modify the likelihood of specified tokens appearing in the\ncompletion. Accepts a json object that maps tokens (specified by their token ID\nin the GPT tokenizer) to an associated bias value from -100 to 100. You can use\nthis tokenizer tool (which works for both GPT-2 and GPT-3) to convert text to\ntoken IDs. Mathematically, the bias is added to the logits generated by the\nmodel prior to sampling. The exact effect will vary per model, but values\nbetween -1 and 1 should decrease or increase likelihood of selection; values\nlike -100 or 100 should result in a ban or exclusive selection of the relevant\ntoken. As an example, you can pass {\"50256\" &#58; -100} to prevent the\n<|endoftext|> token from being generated.",
          "additionalProperties": {
            "format": "int32",
            "type": "integer"
          }
        },
        "user": {
          "type": "string",
          "description": "The ID of the end-user, for use in tracking and rate-limiting."
        },
        "n": {
          "type": "integer",
          "format": "int32",
          "description": "How many snippets to generate for each prompt. Minimum of 1 and maximum of 128\nallowed."
        },
        "logprobs": {
          "type": "integer",
          "format": "int32",
          "description": "Include the log probabilities on the `logprobs` most likely tokens, as well the\nchosen tokens. So for example, if `logprobs` is 10, the API will return a list\nof the 10 most likely tokens. If `logprobs` is 0, only the chosen tokens will\nhave logprobs returned. Minimum of 0 and maximum of 100 allowed."
        },
        "model": {
          "type": "string",
          "description": "The name of the model to use"
        },
        "echo": {
          "type": "boolean",
          "description": "Echo back the prompt in addition to the completion"
        },
        "stop": {
          "type": "array",
          "description": "A sequence which indicates the end of the current document.",
          "items": {
            "type": "string"
          }
        },
        "completion_config": {
          "type": "string",
          "description": "Completion configuration"
        },
        "cache_level": {
          "type": "integer",
          "format": "int32",
          "description": "can be used to disable any server-side caching, 0=no cache, 1=prompt prefix\nenabled, 2=full cache"
        },
        "presence_penalty": {
          "type": "number",
          "format": "float",
          "description": "How much to penalize new tokens based on their existing frequency in the text\nso far. Decreases the model's likelihood to repeat the same line verbatim. Has\nminimum of -2 and maximum of 2."
        },
        "frequency_penalty": {
          "type": "number",
          "format": "float",
          "description": "How much to penalize new tokens based on whether they appear in the text so\nfar. Increases the model's likelihood to talk about new topics."
        },
        "best_of": {
          "type": "integer",
          "format": "int32",
          "description": "How many generations to create server side, and display only the best. Will not\nstream intermediate progress if best_of > 1. Has maximum value of 128."
        }
      },
      "required": [
        "model"
      ]
    },
    "Completions.CompletionsUsage": {
      "type": "object",
      "description": "Measurment of the amount of tokens used in this request and response",
      "properties": {
        "completion_token": {
          "type": "integer",
          "format": "int32",
          "description": "Number of tokens received in the completion"
        },
        "prompt_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "Number of tokens sent in the original request"
        },
        "total_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "Total number of tokens transacted in this request/response"
        }
      },
      "required": [
        "completion_token",
        "prompt_tokens",
        "total_tokens"
      ]
    },
    "Deployment": {
      "type": "object",
      "description": "A specific deployment",
      "properties": {
        "deploymentId": {
          "type": "string",
          "description": "deployment id of the deployed model",
          "readOnly": true
        }
      },
      "required": [
        "deploymentId"
      ]
    },
    "Embeddings.EmbeddingItem": {
      "type": "object",
      "description": "Expected response schema to embeddings object list item request",
      "properties": {
        "object": {
          "type": "string",
          "description": "Name of the field in which the embedding is contained",
          "enum": [
            "embedding"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "embedding": {
          "type": "array",
          "description": "List of embeddings value for the input prompt. These represents a measurement of releated of text strings",
          "items": {
            "type": "number",
            "format": "float"
          }
        },
        "index": {
          "type": "integer",
          "format": "int32",
          "description": "Index of the prompt to which the EmbeddingItem corresponds"
        }
      },
      "required": [
        "object",
        "embedding",
        "index"
      ]
    },
    "Embeddings.Embeddings": {
      "type": "object",
      "description": "Expected response schema to embeddings request",
      "properties": {
        "object": {
          "type": "string",
          "description": "Type of the data field",
          "enum": [
            "list"
          ],
          "x-ms-enum": {
            "modelAsString": false
          }
        },
        "data": {
          "type": "array",
          "description": "Embedding values for the prompts submitted in the request",
          "items": {
            "$ref": "#/definitions/Embeddings.EmbeddingItem"
          },
          "x-ms-identifiers": []
        },
        "model": {
          "type": "string",
          "description": "ID of the model to use"
        },
        "usage": {
          "$ref": "#/definitions/Embeddings.EmbeddingsUsage",
          "description": "Usage counts for tokens input using the embeddings API"
        }
      },
      "required": [
        "object",
        "data",
        "usage"
      ]
    },
    "Embeddings.EmbeddingsOptions": {
      "type": "object",
      "description": "Schema to create a prompt completion from a deployment",
      "properties": {
        "user": {
          "type": "string",
          "description": "The ID of the end-user, for use in tracking and rate-limiting."
        },
        "input_type": {
          "type": "string",
          "description": "input type of embedding search to use"
        },
        "model": {
          "type": "string",
          "description": "ID of the model to use"
        },
        "input": {
          "description": "Input text to get embeddings for, encoded as a string.\nTo get embeddings for multiple inputs in a single request, pass an array of strings.\nEach input must not exceed 2048 tokens in length.\n\nUnless you are embedding code, we suggest replacing newlines (\\n) in your input with a single space,\nas we have observed inferior results when newlines are present."
        }
      },
      "required": [
        "input"
      ]
    },
    "Embeddings.EmbeddingsUsage": {
      "type": "object",
      "description": "Measurment of the amount of tokens used in this request and response",
      "properties": {
        "prompt_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "Number of tokens sent in the original request"
        },
        "total_tokens": {
          "type": "integer",
          "format": "int32",
          "description": "Total number of tokens transacted in this request/response"
        }
      },
      "required": [
        "prompt_tokens",
        "total_tokens"
      ]
    },
    "ServiceApiVersions": {
      "type": "string",
      "enum": [
        "2022-12-01"
      ],
      "x-ms-enum": {
        "name": "ServiceApiVersions",
        "modelAsString": true,
        "values": [
          {
            "name": "v2022_12_01",
            "value": "2022-12-01"
          }
        ]
      }
    }
  },
  "parameters": {
    "Azure.Core.Foundations.ApiVersionParameter": {
      "name": "api-version",
      "in": "query",
      "description": "The API version to use for this operation.",
      "required": true,
      "type": "string",
      "minLength": 1,
      "x-ms-parameter-location": "method",
      "x-ms-client-name": "apiVersion"
    }
  }
}
